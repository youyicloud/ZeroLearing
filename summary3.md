<!-- <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script> -->

## Incorporating visual features into word embeddings: A bimodal autoencoder-based approach

### 写作背景及目的
#### 背景
多模态语义表示是自然语言处理和计算机视觉研究中的一个不断发展的领域。而且最近将感知信息(如视觉特征)和语言特征融合在一起的研究,正在变得越来越热门.

#### 目的
作者提出了一个新颖的用于多模态表征学习的双模自动编码器模型,其中自编码器可以结合对应的视觉特征来增强对应的语言特征向量.同时作者进一步研究了增强型词嵌入在区分正反义词与模糊的相关词时所具有的潜在的效果

### 核心问题
目前多模态语义表示方面主要存在以下几点问题：
1. 没有对单词进行零样本表征学习
2. 没有充分利用有用的资源(如使用图像特征进行增强型词嵌入)

### 现有状况及相关研究
目前的多模态表示学习方法主要可以通过信息的融合或者整合方式来进行分类.作者在论文中主要列举了两类方法.一类是对单词-特征矩阵进行奇异值分解,其中的单词-特征矩阵主要由语言向量和对应的视觉特征向量串联组成.其中语言向量通过Strudel方法生成,然后视觉特征向量使用依赖于BOVW的传统卷积特征提取方式来获得.第二类是简单的进行向量拼接.其中的视觉特征通过卷积神经网络提取,语言特征通过Word2Vec方式提取.但是这些方法都无法处理零样本学习.
为了解决多模态表示背景下的零样本学习问题.Lazaridou等人提出了可以合并视觉特征的skip-gram模型,该模型通过学习共同预测语言和视觉特征来建立单词向量.但是由于该模型是一个联合学习的过程,所以无法独立的使用现在已经存在的独立的语言资源或者相关的视觉特征资源.

### 作者所做的工作
1. 作者提出的ViEW模型解决了多模态表示背景下的零射击表示学习问题,同时该模型没有采用联合学习方法,所以不会产生上述的问题.该模型的核心是一个双模的自编码器,通过设置特定的损失函数来集成双模输入.
2. 该模型在运行时,首先把字嵌入向量送入网络中进行正向计算,然后h2层进行视觉特征与正向计算的词嵌入向量进行合并,并采用H3层向量作为多模态语义表示.

### 方法创新点及局限性

### 实验验证
1. 首先将Printerest 40M数据集中的句子中的单词转换为小写.然后分别在句子的开头与结尾部分添加开始与结束符号.
2. 训练时采用随机梯度下降法,采用256的批次大小,初始学习率为1.0,然后开始最模型进行训练,知道损失不会继续下降为止.
3. 评估时使用训练的嵌入模型来提取短语中的单词的嵌入表示,然后比较原始短语与正短语和负短语之间的余弦距离来判断嵌入表示是否正确.

### 结论
1. 根据最终的测试结果表明,当模型成功的将视觉信息与文本信息融合在一起时,视觉信息可以有效的帮助提高单词嵌入的训练效果.模型A分别在Gold RP10K(黄金标准评估数据集)和RP10M(原始评估数据集)数据集上优于Word2Vec模型9.5%和9.2%。模型C也优于纯文本RNN模型的表现.
2. 权重共享策略可以增强模型将视觉信息融合到词嵌入训练的能力.例如,模型A采用权重共享策略时,其正确率在Gold RP10K(黄金标准评估数据集)和RP10M(原始评估数据集)数据集上分别相比没有采用时高了2.5%与4.8%.
3. 模型A在所有三种模型中表现最佳。它表明,权重分享策略所施加的软监督比直接监督更有效。
4. 在Pinterest40M数据集上训练的所有模型都比在更大纯文本数据集上训练的skip-gram模型表现的更好

### 对自己的启发
1. 我们应当学会从生活中经常接触的数据中整理出自己想要的数据集.