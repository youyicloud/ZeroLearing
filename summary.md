<!-- <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script> -->

## Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly

### 写作背景及目的
#### 背景
因为目前零样本学习在对缺少标记的训练样本分类方面起着越来越重要的作用，所以越来越多的零样本学习方法被提出来了。

#### 目的
分析一下目前的零样本学习现状并且定义一个通用的评价基准

### 核心问题

目前零样本学习的现状主要存在以下几点问题：
1. 目前零样本学习没有一个一致公认的评价基准，导致很难评价新提出来的方法在之前的方法基础上有了多大的进步。
2. 数据集拆分标准不一，导致之前公布的方法所到达的效果也没法直接进行比较。而且如果有人在测试类别上进行预训练会对结果产生比较严重的影响。

### 现有状况
#### 常见的零样本学习方法类别
1. 线性方法(linear learning)
2. 非线性方法(nonlinear compatibility learning)
3. 独立分类器(independent classifier learning)

#### AWA1数据集
因为AWA1没有公开协议，目前不能直接获得原始图片，只能获得一些通过网络提取后的图像特征。

#### AWA2数据集
AWA2数据集具有公开协议协议，同时拥有和AWA1相同数量的图像类别和属性，且所有原始图片都是公开的，可以直接获取。

### 相关研究
#### 早期(Two Stage)
##### 通过属性(attribute)预测
步骤：

1. 预测出图像的一些属性
2. 搜寻具有这些相似的属性的类别

代表性方法:

1. Direct Attribute Prediction(DAP)
2. Indirect Attribute Prediction(IAP)

##### 通过词向量(word vector)预测

步骤:

1. 预测已知类别的后验概率
2. 将图像特征投影到词向量空间(Question)

代表性方法:

1. IAP
2. CONSE

#### 近期的研究
大多数近期的零样本学习方法采用了直接学习一个从图像特征空间到语义空间的映射的方式。

##### 1. SOC
SOC将图像特征映射进语义空间后，然后搜寻最相邻的类别向量。

##### 2. ALE
ALE使用了排序损失函数，来学习图像与属性之间的双线性兼容(compatibility)函数。

##### 3. DeViSE
DeViSE采用了一个更有效的ranking loss来学习一个图像与语义空间线性映射，并且在大型的ImageNet数据集上进行了评估

##### 4. SJE
SJE采用了SVM loss去学习双线性兼容函数，

##### 5. ESZSL
ESZSL采用了square loss

##### 6. SAE
SAE采用了一种语义自动编码器(semantic auto encoder),通过强制将图像特征投影到语义空间来对模型进行正则化。

##### 7. LatEm
LatEm采用了多个线性映射,将SJE的双线性兼容性模型扩展到了分段线性映射.

##### 8. CMT
CMT采用了带有隐藏层的神经网络,学习从图像特征到word2vec的非线性映射.

##### 9. JLSE
JLSE将视觉特征和语义特征映射到两个独立的潜在空间中，并通过学习另一个双线性相容函数来度量它们的相似性。

因为零样本学习在预测时只能使用没有参与训练的类，所以被批评其限制性比较强，所以，有人提出了广义的零样本学习设置，即将零样本学习任务推广到在测试时同时使用参与训练和未参与训练的类。

### 作者所做的工作

#### 评估方法
零样本学习在训练时候，主要目的是通过训练时减少损失函数和正则项，然后学习出一个从输入到输出嵌入的映射。在测试时，零样本学习输入一个未训练过的类别的图片，然后将其进行正确分类，广义的零样本学习可以输入训练与未训练过类别的图片。

##### 线性相容函数的学习
属性标签嵌入(ALE)、深度视觉语义嵌入(Designer)和结构化联合嵌入(SJE)都使用双线相容函数将视觉信息和辅助信息关联起来：
F(x, y; W) = θ(x)<sup>T</sup>Wφ(y)
定义这个函数的目的是对于见过或没见过的类别，衡量图像特征θ(x)和语义表征 等辅助信息ψ(y)之间的相容性（compatibility）。W是所要学习的视觉-语义映射矩阵。

##### 非线性相容函数的学习
1. 潜在嵌入(Latem)
Latem构造了一个分段线性相容函数:F(x, y; W<sub>i</sub>) = maxθ(x)<sup>T</sup>W<sub>i</sub>φ(y),其中每个W<sub>i</sub>对数据建立了不同的视觉特性，并且选择用于映射的矩阵是一个隐藏变量.Latem采用了的排序损失函数和随机梯度下降优化器。
2. 跨模态迁移(CMT)
CMT首先将图像映射到了类名的语义空间，其中这个映射是含有tanh的非线性神经网络映射函数。最后再通过一种是否是新类的检测机制，可以将图像分配给看不见或看不见的类。

##### 中间属性分类的研究
1. DAP首先为每个属性学习了一个概率分类器，并通过组合这些学习得到的属性分类器的分数来进行类别预测。
2. IAP首先通过预测每个训练类的概率，然后乘以类属性矩阵来间接估计图像的属性概率。

#### 数据集相关
作者从大量的的零样本学习数据集中，我们选择了两个粗粒度数据集(一个小规模和一个中等规模)，两个中等规模的细粒度数据集，且都包含属性信息。还有一个是没有包含属性信息的大规模数据集。

##### 含有属性信息的数据集
1. Attribute Pascal and Yahoo (aPY)是一个具有64个属性的小规模粗粒度数据集。在32个类中，作者选择了20个Pascal类用于训练（我们随机选择5个用于验证），12个Yahoo类用于测试。
2. 因为AWA1数据集的图像不公开，作者收集了和AWA1相同的50类别的的37,322幅图像作为AWA2数据集，同时AWA2与AWA1数据集相比，图像数量以及图像特征的分布。

##### 大规模数据集ImageNet
作者还评估了所有方法在大规模数据集ImageNet上的性能。ImageNet具有21k个类别，但是每个类别所含有的图片数差别非常大。从ImageNet中可以提取出一个具有1K类，每个类包含大约1000个图像的平衡子集。作者没有采用像以前一样的把平衡子集拆分成测试集和训练集的方法，而是将平衡子集作为训练样本，然后把剩下的其他类别的样本作为测试数据进行测试。

#### 评估协议

##### 图像和类的嵌入
1. 作者使用在ImageNet上使用1K平衡子集上预训练的ResNet-101模型提取特征，将输入图像进行前向计算后得到的2048维的池化单元作为图片嵌入.
2. 对于aPY，AWA1，AWA2，CUB和SUN数据集，作者使用了通过判断属性是否存在得出的二进制编码。而对于不含有属性信息的ImageNet数据集，作者使用了在的维基百科语料上训练过的Word2Vec来提取类嵌入信息。

##### 数据集的拆分
在零样本学习中，在测试时的图像类别都应该是没有参与训练过的。但是用于提取他在的ResNet模型之前曾在ImageNet数据集上预训练过。同时，作者也主要到了有7个aPY测试类和6个AWA1测试类，都被包含在了ImageNet平衡子集中。所以作者提出了两种数据集划分方式，一种是和之前的一样的标准划分(SS)，还有一种是作者新提出来的建议的划分(PS)。在PS划分中，确保没有任何测试类出现在ImageNet 1K平衡子集中。同时作者也保持了SS和PS中的类别数相同。

#### 评估标准
1. 如果采用对所有图像的TOP-1准确率进行评估，就可能会在样本比较多的类上得到的平均准确率的精度会比较高。然而，作者也希望在样本比较小的类别上得到的准确率也比较精准。所以,作者采用了以下方式来度量每个类的平均top-1准确率：
$$ acc=\frac{1}{\left \| Y \right \|}\sum_{c=1}^{\left \| Y \right \|}\frac{类别c中预测正确的数量}{类别c中总的数量} $$




### 方法创新点及局限性

### 实验验证

### 对自己的启发